<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dengyang</title>
  
  <subtitle>dy</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://120224.com/"/>
  <updated>2018-12-28T18:18:45.834Z</updated>
  <id>http://120224.com/</id>
  
  <author>
    <name>Young Teng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>网站闲置了一年多之后的感想</title>
    <link href="http://120224.com/2018/12/27/the_thought_of_no_manage_web_one_half_year_later/"/>
    <id>http://120224.com/2018/12/27/the_thought_of_no_manage_web_one_half_year_later/</id>
    <published>2018-12-26T23:35:59.000Z</published>
    <updated>2018-12-28T18:18:45.834Z</updated>
    
    <content type="html"><![CDATA[<p>其实我在2017年06/07月份就应经把120224.com这个域名注册了,<br>同时也在同事彭川大神的影响下开始接触hexo+github.io这个静态博客系统.<br>之后也是随意搞搞搞,没有什么大的动作.<br>后来09月23日左右又开始跟着李沐大神学习Gluon深度学习课程,这些东西也就不了了之了.<br>最近是看到别人的博客时,发现别人的博客挺漂亮的就想到了自己的.<br>自己的一直没有经营,还是以前的老theme.因为之前修过了mac-pro,<br>导致自己的博客文件没有备份保存下来,同时又想直接摒弃以前的主题,<br>所以最近就直接又新建了一个新的主题.<br>以后这个博客还是可以多来记录记录自己的技术学习过程和自己的生活点点滴滴的,<br>也是极好的呢.同时自己也有喜欢记录的习惯,就是偶尔总是拖延症附体,<br>所以也都是断断续续不系统的记录.有时候也总是想改掉这个坏毛病,<br>所以这个博客也就成了自己改掉坏习惯的一个”见证人”吧.<br>后面的路还很长,希望自己勿忘初心,砥砺前行,脚踏实地的,<br>千万不要再次好高骛远了.加油!<br>    邓先森 2018-12-27 08:20 石榴庄</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;其实我在2017年06/07月份就应经把120224.com这个域名注册了,&lt;br&gt;同时也在同事彭川大神的影响下开始接触hexo+github.io这个静态博客系统.&lt;br&gt;之后也是随意搞搞搞,没有什么大的动作.&lt;br&gt;后来09月23日左右又开始跟着李沐大神学习Gluon深
      
    
    </summary>
    
      <category term="随笔" scheme="http://120224.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="感想" scheme="http://120224.com/tags/%E6%84%9F%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>&lt;(￣︶￣)&gt; 网站更新情况记录 &lt;(￣︶￣)&gt;</title>
    <link href="http://120224.com/2017/12/29/the_logs_of_web_update/"/>
    <id>http://120224.com/2017/12/29/the_logs_of_web_update/</id>
    <published>2017-12-28T18:12:01.000Z</published>
    <updated>2018-12-28T19:40:45.335Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2018-12-29"><a href="#2018-12-29" class="headerlink" title="2018-12-29:"></a>2018-12-29:</h1><p>1.添加置顶功能.<br>2.增添了日志发表时间,以前版本只到日期.<br>3.添加了吴恩达课程和AstonZhang的友链.<br>4.更改”沐神”为”李沐”,描述”~ 亚马逊 &amp; MXNet &amp; Gluon发起者 ~”改为”~ 亚马逊首席（principal）科学家，美国卡内基梅隆大学计算机系博士。~”.<br>5.更改”~ B站课程 (经典) ~”为”~ B站《动手学深度学习》课程 (经典) ~”.</p><h1 id="2018-12-28"><a href="#2018-12-28" class="headerlink" title="2018-12-28:"></a>2018-12-28:</h1><p>1.将网站与七牛云连结,避免日后写文章添加图片的繁琐.</p><h1 id="2018-12-27"><a href="#2018-12-27" class="headerlink" title="2018-12-27:"></a>2018-12-27:</h1><p>1.添加评论功能,用了韩国的”来必力”.经过测试移动端貌似没有问题,就是pc端可能存在问题,To-do.</p><h1 id="2018-12-26"><a href="#2018-12-26" class="headerlink" title="2018-12-26:"></a>2018-12-26:</h1><p>1.将Next主题更新为Pure主题,重新开始.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;2018-12-29&quot;&gt;&lt;a href=&quot;#2018-12-29&quot; class=&quot;headerlink&quot; title=&quot;2018-12-29:&quot;&gt;&lt;/a&gt;2018-12-29:&lt;/h1&gt;&lt;p&gt;1.添加置顶功能.&lt;br&gt;2.增添了日志发表时间,以前版本只到日期.&lt;b
      
    
    </summary>
    
      <category term="网站更新" scheme="http://120224.com/categories/%E7%BD%91%E7%AB%99%E6%9B%B4%E6%96%B0/"/>
    
    
      <category term="hexo" scheme="http://120224.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>kaggle上的房价预测竞赛练习,个人最好成绩达到0.15538 &lt;未完待续&gt;</title>
    <link href="http://120224.com/2017/09/24/test-of-kaggle-house-prices-predict/"/>
    <id>http://120224.com/2017/09/24/test-of-kaggle-house-prices-predict/</id>
    <published>2017-09-23T17:25:24.000Z</published>
    <updated>2018-12-29T17:56:20.058Z</updated>
    
    <content type="html"><![CDATA[<h1 id="coding-utf-8"><a href="#coding-utf-8" class="headerlink" title="-- coding: utf-8 --"></a>-<em>- coding: utf-8 -</em>-</h1><h1 id="Time-2017-09-23-3-14-PM"><a href="#Time-2017-09-23-3-14-PM" class="headerlink" title="@Time    : 2017/09/23 3:14 PM"></a>@Time    : 2017/09/23 3:14 PM</h1><h1 id="Author-dengyang"><a href="#Author-dengyang" class="headerlink" title="@Author  : dengyang"></a>@Author  : dengyang</h1><h1 id="Email-youngteng-163-com"><a href="#Email-youngteng-163-com" class="headerlink" title="@Email   : youngteng@163.com"></a>@Email   : <a href="mailto:youngteng@163.com" target="_blank" rel="noopener">youngteng@163.com</a></h1><h1 id="File-housePredict-py"><a href="#File-housePredict-py" class="headerlink" title="@File    : housePredict.py"></a>@File    : housePredict.py</h1><h1 id="Software-PyCharm"><a href="#Software-PyCharm" class="headerlink" title="@Software: PyCharm"></a>@Software: PyCharm</h1><h1 id="1-获取和读取数据集"><a href="#1-获取和读取数据集" class="headerlink" title="1.获取和读取数据集"></a>1.获取和读取数据集</h1><h1 id="导包"><a href="#导包" class="headerlink" title="导包"></a>导包</h1><p>import gluonbook as gb<br>from mxnet import autograd,nd,gluon,init<br>from mxnet.gluon import data as gdata,loss as gloss,nn<br>import numpy as np<br>import pandas as pd</p><h1 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h1><p>train_data = pd.read_csv(‘./train.csv’)<br>test_data = pd.read_csv(‘./test.csv’)</p><h1 id="查看下train和test数据的shape-规格大小"><a href="#查看下train和test数据的shape-规格大小" class="headerlink" title="查看下train和test数据的shape,规格大小"></a>查看下train和test数据的shape,规格大小</h1><p>print(train_data.shape)<br>print(test_data.shape)</p><h1 id="查看下训练样本前四个样本的前四个特征-后两个特征和标签"><a href="#查看下训练样本前四个样本的前四个特征-后两个特征和标签" class="headerlink" title="查看下训练样本前四个样本的前四个特征,后两个特征和标签"></a>查看下训练样本前四个样本的前四个特征,后两个特征和标签</h1><p>‘’’<br>iloc和loc的区别：<br>    iloc，完全基于位置的索引.<br>    iloc的用法完全和numpy中的数字索引一样，开闭区间的逻辑也和Python是相同的。<br>    要注意的是，如果iloc方括号中直接给定一个数字或者一个slice的话，默认索引的是行。<br>    其中数字的情况会返回一个Series</p><pre><code>iloc主要使用数字来索引数据，而不能使用字符型的标签来索引数据。而loc则刚好相反，只能使用字符型标签来索引数据，不能使用数字来索引数据，不过有特殊情况，当数据框dataframe的行标签或者列标签为数字，loc就可以来其来索引。</code></pre><p>‘’’<br>print(train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]])</p><h1 id="将所有数据的训练和测试数据的79个特征按样本连结"><a href="#将所有数据的训练和测试数据的79个特征按样本连结" class="headerlink" title="将所有数据的训练和测试数据的79个特征按样本连结"></a>将所有数据的训练和测试数据的79个特征按样本连结</h1><p>all_features = pd.concat((train_data.iloc[:,1:-1],test_data.iloc[:,1:]))</p><h1 id="2-预处理数据"><a href="#2-预处理数据" class="headerlink" title="2.预处理数据"></a>2.预处理数据</h1><h1 id="对连续数值的特征做标准化-假设特征在整个数据集上的均值μ-标准差σ"><a href="#对连续数值的特征做标准化-假设特征在整个数据集上的均值μ-标准差σ" class="headerlink" title="对连续数值的特征做标准化:假设特征在整个数据集上的均值μ,标准差σ."></a>对连续数值的特征做标准化:假设特征在整个数据集上的均值μ,标准差σ.</h1><h1 id="我们可以将特征中每个值先减去μ-再除以σ得到标准化后的每一个特征值"><a href="#我们可以将特征中每个值先减去μ-再除以σ得到标准化后的每一个特征值" class="headerlink" title="我们可以将特征中每个值先减去μ,再除以σ得到标准化后的每一个特征值,"></a>我们可以将特征中每个值先减去μ,再除以σ得到标准化后的每一个特征值,</h1><h1 id="缺失值替换成该特征的均值"><a href="#缺失值替换成该特征的均值" class="headerlink" title="缺失值替换成该特征的均值."></a>缺失值替换成该特征的均值.</h1><h1 id="下面的含义是-all-features的类型如果不是object类型则将特征的索引-index-传递给numeric-features"><a href="#下面的含义是-all-features的类型如果不是object类型则将特征的索引-index-传递给numeric-features" class="headerlink" title="下面的含义是:all_features的类型如果不是object类型则将特征的索引(index)传递给numeric_features"></a>下面的含义是:all_features的类型如果不是object类型则将特征的索引(index)传递给numeric_features</h1><p>numeric_features = all_features.dtypes[all_features.dtypes != ‘object’].index<br>‘’’<br>apply:TO-DO<br>‘’’<br>all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))</p><h1 id="下面代码含义-将all-features中含有NA的值用all-features的均值进行填充"><a href="#下面代码含义-将all-features中含有NA的值用all-features的均值进行填充" class="headerlink" title="下面代码含义:将all_features中含有NA的值用all_features的均值进行填充."></a>下面代码含义:将all_features中含有NA的值用all_features的均值进行填充.</h1><p>all_features = all_features.fillna(all_features.mean())</p><h1 id="将离散数值转换成指示特征-如-特征A里面有两个不同的离散值1和2-那么这一步转换"><a href="#将离散数值转换成指示特征-如-特征A里面有两个不同的离散值1和2-那么这一步转换" class="headerlink" title="将离散数值转换成指示特征.如:特征A里面有两个不同的离散值1和2,那么这一步转换"></a>将离散数值转换成指示特征.如:特征A里面有两个不同的离散值1和2,那么这一步转换</h1><h1 id="将去掉A特征-并新加两个新特征A-1和A-2-其值为0或1"><a href="#将去掉A特征-并新加两个新特征A-1和A-2-其值为0或1" class="headerlink" title="将去掉A特征,并新加两个新特征A_1和A_2,其值为0或1."></a>将去掉A特征,并新加两个新特征A_1和A_2,其值为0或1.</h1><h1 id="dummy-na-True-将缺失值也当做合法的特征值并为其创建指示特征"><a href="#dummy-na-True-将缺失值也当做合法的特征值并为其创建指示特征" class="headerlink" title="dummy_na=True,将缺失值也当做合法的特征值并为其创建指示特征"></a>dummy_na=True,将缺失值也当做合法的特征值并为其创建指示特征</h1><p>all_features = pd.get_dummies(all_features,dummy_na=True)<br>print(all_features.shape)</p><h1 id="此时将特征从79维增加到331维"><a href="#此时将特征从79维增加到331维" class="headerlink" title="此时将特征从79维增加到331维"></a>此时将特征从79维增加到331维</h1><h1 id="通过values属性得到NumPy格式的数据-并转成NDArray方便后继训练"><a href="#通过values属性得到NumPy格式的数据-并转成NDArray方便后继训练" class="headerlink" title="通过values属性得到NumPy格式的数据,并转成NDArray方便后继训练"></a>通过values属性得到NumPy格式的数据,并转成NDArray方便后继训练</h1><p>n_train = train_data.shape[0]<br>train_features = nd.array(all_features[:n_train].values)</p><h1 id="因为之前将train和test所有的数据都合并成了一个文件"><a href="#因为之前将train和test所有的数据都合并成了一个文件" class="headerlink" title="因为之前将train和test所有的数据都合并成了一个文件,"></a>因为之前将train和test所有的数据都合并成了一个文件,</h1><h1 id="现在通过all-features-n-train-和all-features-n-train-将他们分开"><a href="#现在通过all-features-n-train-和all-features-n-train-将他们分开" class="headerlink" title="现在通过all_features[:n_train]和all_features[n_train:]将他们分开"></a>现在通过all_features[:n_train]和all_features[n_train:]将他们分开</h1><p>test_features = nd.array(all_features[n_train:].values)<br>train_labels = nd.array(train_data.SalePrice.values).reshape((-1,1))</p><h1 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3.训练模型"></a>3.训练模型</h1><h1 id="使用基本线性回归模型和平方损失函数训练模型"><a href="#使用基本线性回归模型和平方损失函数训练模型" class="headerlink" title="使用基本线性回归模型和平方损失函数训练模型"></a>使用基本线性回归模型和平方损失函数训练模型</h1><p>loss = gloss.L2Loss()</p><p>def get_net():<br>    net = nn.Sequential()<br>    net.add(nn.Dense(1))<br>    net.initialize()<br>    return net</p><h1 id="定义此次比赛中用来评价模型的对数均方根误差"><a href="#定义此次比赛中用来评价模型的对数均方根误差" class="headerlink" title="定义此次比赛中用来评价模型的对数均方根误差."></a>定义此次比赛中用来评价模型的对数均方根误差.</h1><p>def log_rmse(net,features,labels):</p><pre><code># 将小于1的值设成1,使得取对数时数值更稳定&apos;&apos;&apos;Numpy中clip函数的使用.numpy.clip(a, a_min, a_max, out=None)其中a是一个数组，后面两个参数分别表示最小和最大值，也就是说clip这个函数将将数组中的元素限制在a_min, a_max之间，大于a_max的就使得它等于 a_max，小于a_min,的就使得它等于a_min。&apos;&apos;&apos;clipped_preds = nd.clip(net(features),1,float(&apos;inf&apos;))rmse = nd.sqrt(2 * loss(clipped_preds.log(),labels.log()).mean())# asscalar():Convert an array of size 1 to its scalar equivalent.# 将大小为1的数组转换为其标量等效值return rmse.asscalar()</code></pre><p>def train(net,train_features,train_labels,test_features,test_labels,<br>          num_epochs,learning_rate,weight_decay,batch_size):<br>    train_ls,test_ls = [],[]<br>    train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features,train_labels),batch_size,shuffle=True)</p><pre><code># 使用Adam优化算法trainer = gluon.Trainer(net.collect_params(),&apos;adam&apos;,{&apos;learning_rate&apos;:learning_rate,&apos;wd&apos;:weight_decay})for epoch in range(num_epochs):    for X,y in train_iter:        with autograd.record():            l = loss(net(X),y)        l.backward()        trainer.step(batch_size)    train_ls.append(log_rmse(net,train_features,train_labels))    if test_labels is not None:        test_ls.append(log_rmse(net,test_features,test_labels))return train_ls,test_ls</code></pre><h1 id="4-K折交叉验证"><a href="#4-K折交叉验证" class="headerlink" title="4.K折交叉验证"></a>4.K折交叉验证</h1><p>def get_k_fold_data(k,i,X,y):</p><pre><code># 返回第i折交叉验证时所需要的训练和验证数据# 断言函数,做下判断,如果是false就报错退出assert k &gt; 1# 均分一下数据fold_size = X.shape[0] // kX_train,y_train = None,Nonefor j in range(k):    # slice() 函数实现切片对象，主要用在切片操作函数里的参数传递。    idx = slice(j * fold_size,(j + 1) * fold_size)    X_part,y_part = X[idx,:],y[idx]    if j == 1:        X_valid,y_valid = X_part,y_part    elif X_train is None:        X_train,y_train = X_part,y_part    else:        X_train = nd.concat(X_train,X_part,dim=0)        y_train = nd.concat(y_train,y_part,dim=0)return X_train,y_train,X_valid,y_valid</code></pre><h1 id="K折交叉验证我们训练k次并返回训练和验证的平均误差"><a href="#K折交叉验证我们训练k次并返回训练和验证的平均误差" class="headerlink" title="K折交叉验证我们训练k次并返回训练和验证的平均误差"></a>K折交叉验证我们训练k次并返回训练和验证的平均误差</h1><p>def k_fold(k,X_train,y_train,num_epochs,learning_rate,weight_decay,batch_size):<br>    train_l_sum,valid_l_sum = 0,0<br>    for i in range(k):<br>        data = get_k_fold_data(k,i,X_train,y_train)<br>        net = get_net()<br>        train_ls,valid_ls = train(net,*data,num_epochs,learning_rate,weight_decay,batch_size)<br>        train_l_sum += train_ls[-1]<br>        valid_l_sum += valid_ls[-1]<br>        if i == 0:<br>            ‘’’<br>            我们先定义作图函数semilogy，其中y轴使用了对数尺度。<br>            def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,<br>                         legend=None, figsize=(3.5, 2.5)):<br>                gb.set_figsize(figsize)<br>                gb.plt.xlabel(x_label)<br>                gb.plt.ylabel(y_label)<br>                gb.plt.semilogy(x_vals, y_vals)<br>                if x2_vals and y2_vals:<br>                    gb.plt.semilogy(x2_vals, y2_vals, linestyle=’:’)<br>                    gb.plt.legend(legend)<br>            ‘’’<br>            gb.semilogy(range(1,num_epochs + 1),train_ls,’epochs’,’rmse’,range(1,num_epochs +1),valid_ls,[‘train’,’valid’])<br>        print(‘fold %d,train rmse: %f,valid rmse: %f’ % (i,train_ls[-1],valid_ls[-1]))</p><pre><code>return train_l_sum / k,valid_l_sum / k</code></pre><h1 id="5-模型选择"><a href="#5-模型选择" class="headerlink" title="5.模型选择"></a>5.模型选择</h1><h1 id="我们使用一组未经调优的超参数并计算交叉验证误差。你可以改动这些超参数来尽可能减小平均测试误差。"><a href="#我们使用一组未经调优的超参数并计算交叉验证误差。你可以改动这些超参数来尽可能减小平均测试误差。" class="headerlink" title="我们使用一组未经调优的超参数并计算交叉验证误差。你可以改动这些超参数来尽可能减小平均测试误差。"></a>我们使用一组未经调优的超参数并计算交叉验证误差。你可以改动这些超参数来尽可能减小平均测试误差。</h1><p>k,num_epochs,lr,weight_decay,batch_size = 10,100,5,0,64<br>train_l,valid_l = k_fold(k,train_features,train_labels,num_epochs,lr,<br>                         weight_decay,batch_size)<br>print(‘%d-fold validation: avg train rmse: %f,avg valid rmse: %f’ % (k,train_l,valid_l))<br>‘’’<br>有时候你会发现一组参数的训练误差可以达到很低，但是在K折交叉验证上的误差可能反而较高。<br>这种现象很可能是由于过拟合造成的。因此，当训练误差降低时，我们要观察K折交叉验证上的<br>误差是否也相应降低。<br>‘’’</p><h1 id="6-预测并在kaggle提交结果"><a href="#6-预测并在kaggle提交结果" class="headerlink" title="6.预测并在kaggle提交结果"></a>6.预测并在kaggle提交结果</h1><p>def train_and_pred(train_features,test_features,train_labels,test_data,<br>                   num_epochs,lr,weight_decay,batch_size):<br>    net = get_net()<br>    train_ls,_ = train(net,train_features,train_labels,None,None,<br>                       num_epochs,lr,weight_decay,batch_size)<br>    gb.semilogy(range(1,num_epochs + 1),train_ls,’epochs’,’rmse’)<br>    print(‘train rmse %f’ % train_ls[-1])<br>    preds = net(test_features).asnumpy()<br>    test_data[‘SalePrice’] = pd.Series(preds.reshape(1,-1)[0])<br>    submission = pd.concat([test_data[‘Id’],test_data[‘SalePrice’]],axis=1)<br>    submission.to_csv(‘submission.csv’,index=False)</p><p>train_and_pred(train_features,test_features,train_labels,test_data,<br>               num_epochs,lr,weight_decay,batch_size)<br>‘’’<br>上述代码执行完之后会生成一个“submission.csv”文件。<br>这个文件是符合 Kaggle 比赛要求的提交格式的。这时，<br>我们可以在 Kaggle 上把我们预测得出的结果进行提交，<br>并且查看与测试数据集上真实房价（标签）的误差。具体<br>来说有以下几个步骤：你需要登录 Kaggle 网站，访问<br>房价预测比赛网页，并点击右侧“Submit Predictions”<br>或“Late Submission”按钮。然后，点击页面下方<br>“Upload Submission File”图标所在的虚线框选择<br>需要提交的预测结果文件。最后，点击页面最下方的<br>“Make Submission”按钮就可以查看结果了<br>‘’’</p><p>参数[10,100,5,0,64]运行结果:</p><p>fold 0,train rmse: 0.166232,valid rmse: 0.144298<br>fold 1,train rmse: 0.166070,valid rmse: 0.144265<br>fold 2,train rmse: 0.166147,valid rmse: 0.144306<br>fold 3,train rmse: 0.166064,valid rmse: 0.144525<br>fold 4,train rmse: 0.165943,valid rmse: 0.144174<br>fold 5,train rmse: 0.166049,valid rmse: 0.144230<br>fold 6,train rmse: 0.166298,valid rmse: 0.144140<br>fold 7,train rmse: 0.166498,valid rmse: 0.144192<br>fold 8,train rmse: 0.165994,valid rmse: 0.144347<br>fold 9,train rmse: 0.165646,valid rmse: 0.143963<br>10-fold validation: avg train rmse: 0.166094,avg valid rmse: 0.144244</p><p>参数[10,150,5,0,64]运行结果:<br>fold 0,train rmse: 0.150604,valid rmse: 0.128320<br>fold 1,train rmse: 0.150390,valid rmse: 0.128391<br>fold 2,train rmse: 0.150571,valid rmse: 0.128409<br>fold 3,train rmse: 0.150316,valid rmse: 0.128166<br>fold 4,train rmse: 0.150575,valid rmse: 0.128311<br>fold 5,train rmse: 0.150286,valid rmse: 0.128477<br>fold 6,train rmse: 0.150312,valid rmse: 0.128338<br>fold 7,train rmse: 0.150612,valid rmse: 0.128469<br>fold 8,train rmse: 0.150454,valid rmse: 0.128422<br>fold 9,train rmse: 0.150375,valid rmse: 0.128145<br>10-fold validation: avg train rmse: 0.150450,avg valid rmse: 0.128345<br>train rmse 0.145164</p><p>参数[10,165,5,0,50]运行结果:<br>fold 0,train rmse: 0.139469,valid rmse: 0.120657<br>fold 1,train rmse: 0.139487,valid rmse: 0.120587<br>fold 2,train rmse: 0.139366,valid rmse: 0.120478<br>fold 3,train rmse: 0.139568,valid rmse: 0.120741<br>fold 4,train rmse: 0.139651,valid rmse: 0.120759<br>fold 5,train rmse: 0.139555,valid rmse: 0.120640<br>fold 6,train rmse: 0.139403,valid rmse: 0.120650<br>fold 7,train rmse: 0.139626,valid rmse: 0.120719<br>fold 8,train rmse: 0.139548,valid rmse: 0.120652<br>fold 9,train rmse: 0.139596,valid rmse: 0.120694<br>10-fold validation: avg train rmse: 0.139527,avg valid rmse: 0.120658<br>train rmse 0.135256</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;coding-utf-8&quot;&gt;&lt;a href=&quot;#coding-utf-8&quot; class=&quot;headerlink&quot; title=&quot;-- coding: utf-8 --&quot;&gt;&lt;/a&gt;-&lt;em&gt;- coding: utf-8 -&lt;/em&gt;-&lt;/h1&gt;&lt;h1 id=&quot;Ti
      
    
    </summary>
    
      <category term="动手学深度学习" scheme="http://120224.com/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="DeepLearning" scheme="http://120224.com/tags/DeepLearning/"/>
    
      <category term="MXNet" scheme="http://120224.com/tags/MXNet/"/>
    
      <category term="Gluon" scheme="http://120224.com/tags/Gluon/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://120224.com/2017/06/22/hello-world/"/>
    <id>http://120224.com/2017/06/22/hello-world/</id>
    <published>2017-06-22T05:14:25.000Z</published>
    <updated>2018-12-28T18:18:27.445Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="技术" scheme="http://120224.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="hexo" scheme="http://120224.com/tags/hexo/"/>
    
  </entry>
  
</feed>
