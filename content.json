{"meta":{"title":"dengyang","subtitle":"dy","description":"120224.com# dengyang Deep Learning","author":"Young Teng","url":"http://120224.com"},"pages":[{"title":"友情链接","date":"2018-12-27T14:27:17.177Z","updated":"2018-12-27T14:27:17.177Z","comments":true,"path":"index.html","permalink":"http://120224.com/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2018-12-27T14:29:38.588Z","updated":"2018-12-27T14:29:38.588Z","comments":false,"path":"/404.html","permalink":"http://120224.com//404.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-12-27T14:29:38.586Z","updated":"2018-12-27T14:29:38.585Z","comments":true,"path":"links/index.html","permalink":"http://120224.com/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-12-27T14:29:38.591Z","updated":"2018-12-27T14:29:38.591Z","comments":false,"path":"categories/index.html","permalink":"http://120224.com/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2018-12-28T19:37:08.656Z","updated":"2018-12-28T19:37:08.656Z","comments":true,"path":"about/index.html","permalink":"http://120224.com/about/index.html","excerpt":"","text":"个人详细介绍:一个矛盾纠结体处女座的苛求 + 天秤座的纠结一个没事总想胡乱鼓捣鼓捣的家伙爱好: 偶尔看看书,写些东西,发呆想写本关于自己的书,以后会更新在这个网站下 QQ: 568757336GithubID: 54dengyangWeChat: youngteng0923E-mail: youngteng@163.com"},{"title":"标签","date":"2018-12-27T14:29:38.585Z","updated":"2018-12-27T14:29:38.584Z","comments":false,"path":"tags/index.html","permalink":"http://120224.com/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-12-27T14:29:38.579Z","updated":"2018-12-27T14:29:38.579Z","comments":false,"path":"repository/index.html","permalink":"http://120224.com/repository/index.html","excerpt":"","text":""},{"title":"书单","date":"2018-12-27T14:29:38.582Z","updated":"2018-12-27T14:29:38.582Z","comments":false,"path":"books/index.html","permalink":"http://120224.com/books/index.html","excerpt":"","text":""}],"posts":[{"title":"网站闲置了一年多之后的感想","slug":"the_thought_of_no_manage_web_one_half_year_later","date":"2018-12-26T23:35:59.000Z","updated":"2018-12-28T18:18:45.834Z","comments":true,"path":"2018/12/27/the_thought_of_no_manage_web_one_half_year_later/","link":"","permalink":"http://120224.com/2018/12/27/the_thought_of_no_manage_web_one_half_year_later/","excerpt":"","text":"其实我在2017年06/07月份就应经把120224.com这个域名注册了,同时也在同事彭川大神的影响下开始接触hexo+github.io这个静态博客系统.之后也是随意搞搞搞,没有什么大的动作.后来09月23日左右又开始跟着李沐大神学习Gluon深度学习课程,这些东西也就不了了之了.最近是看到别人的博客时,发现别人的博客挺漂亮的就想到了自己的.自己的一直没有经营,还是以前的老theme.因为之前修过了mac-pro,导致自己的博客文件没有备份保存下来,同时又想直接摒弃以前的主题,所以最近就直接又新建了一个新的主题.以后这个博客还是可以多来记录记录自己的技术学习过程和自己的生活点点滴滴的,也是极好的呢.同时自己也有喜欢记录的习惯,就是偶尔总是拖延症附体,所以也都是断断续续不系统的记录.有时候也总是想改掉这个坏毛病,所以这个博客也就成了自己改掉坏习惯的一个”见证人”吧.后面的路还很长,希望自己勿忘初心,砥砺前行,脚踏实地的,千万不要再次好高骛远了.加油! 邓先森 2018-12-27 08:20 石榴庄","categories":[{"name":"随笔","slug":"随笔","permalink":"http://120224.com/categories/随笔/"}],"tags":[{"name":"感想","slug":"感想","permalink":"http://120224.com/tags/感想/"}]},{"title":"<(￣︶￣)> 网站更新情况记录 <(￣︶￣)>","slug":"the_logs_of_web_update","date":"2017-12-28T18:12:01.000Z","updated":"2018-12-31T17:08:52.093Z","comments":true,"path":"2017/12/29/the_logs_of_web_update/","link":"","permalink":"http://120224.com/2017/12/29/the_logs_of_web_update/","excerpt":"","text":"2019-01-01:1.添加了收录百度的功能,确保网站后期能被检索到.2.增加了www域名解析,以前120224.com可以访问,而www.120224.com不能访问. 2018-12-29:1.添加置顶功能.2.增添了日志发表时间,以前版本只到日期.3.添加了吴恩达课程和AstonZhang的友链.4.更改”沐神”为”李沐”,描述”~ 亚马逊 &amp; MXNet &amp; Gluon发起者 ~”改为”~ 亚马逊首席（principal）科学家，美国卡内基梅隆大学计算机系博士。~”.5.更改”~ B站课程 (经典) ~”为”~ B站《动手学深度学习》课程 (经典) ~”. 2018-12-28:1.将网站与七牛云连结,避免日后写文章添加图片的繁琐. 2018-12-27:1.添加评论功能,用了韩国的”来必力”.经过测试移动端貌似没有问题,就是pc端可能存在问题,To-do. 2018-12-26:1.将Next主题更新为Pure主题,重新开始.","categories":[{"name":"网站更新","slug":"网站更新","permalink":"http://120224.com/categories/网站更新/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://120224.com/tags/hexo/"}]},{"title":"kaggle上的房价预测竞赛练习,个人最好成绩达到0.15538","slug":"test-of-kaggle-house-prices-predict","date":"2017-09-23T17:25:24.000Z","updated":"2018-12-30T17:34:37.163Z","comments":true,"path":"2017/09/24/test-of-kaggle-house-prices-predict/","link":"","permalink":"http://120224.com/2017/09/24/test-of-kaggle-house-prices-predict/","excerpt":"","text":"&lt;未完待续&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201# -*- coding: utf-8 -*-# @Time : 2018/12/29 3:14 PM# @Author : dengyang# @Email : youngteng@163.com# @File : housePredict.py# @Software: PyCharm# 1.获取和读取数据集# 导包import gluonbook as gbfrom mxnet import autograd,nd,gluon,initfrom mxnet.gluon import data as gdata,loss as gloss,nnimport numpy as npimport pandas as pd# 读取数据train_data = pd.read_csv('./train.csv')test_data = pd.read_csv('./test.csv')# 查看下train和test数据的shape,规格大小print(train_data.shape)print(test_data.shape)# 查看下训练样本前四个样本的前四个特征,后两个特征和标签'''iloc和loc的区别： iloc，完全基于位置的索引. iloc的用法完全和numpy中的数字索引一样，开闭区间的逻辑也和Python是相同的。 要注意的是，如果iloc方括号中直接给定一个数字或者一个slice的话，默认索引的是行。 其中数字的情况会返回一个Series iloc主要使用数字来索引数据，而不能使用字符型的标签来索引数据。 而loc则刚好相反，只能使用字符型标签来索引数据，不能使用数字来 索引数据，不过有特殊情况，当数据框dataframe的行标签或者列标 签为数字，loc就可以来其来索引。'''print(train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]])# 将所有数据的训练和测试数据的79个特征按样本连结all_features = pd.concat((train_data.iloc[:,1:-1],test_data.iloc[:,1:]))# 2.预处理数据# 对连续数值的特征做标准化:假设特征在整个数据集上的均值μ,标准差σ.# 我们可以将特征中每个值先减去μ,再除以σ得到标准化后的每一个特征值,# 缺失值替换成该特征的均值.# 下面的含义是:all_features的类型如果不是object类型则将特征的索引(index)传递给numeric_featuresnumeric_features = all_features.dtypes[all_features.dtypes != 'object'].index'''apply:TO-DO'''all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))# 下面代码含义:将all_features中含有NA的值用all_features的均值进行填充.all_features = all_features.fillna(all_features.mean())# 将离散数值转换成指示特征.如:特征A里面有两个不同的离散值1和2,那么这一步转换# 将去掉A特征,并新加两个新特征A_1和A_2,其值为0或1.# dummy_na=True,将缺失值也当做合法的特征值并为其创建指示特征all_features = pd.get_dummies(all_features,dummy_na=True)print(all_features.shape)# 此时将特征从79维增加到331维# 通过values属性得到NumPy格式的数据,并转成NDArray方便后继训练n_train = train_data.shape[0]train_features = nd.array(all_features[:n_train].values)# 因为之前将train和test所有的数据都合并成了一个文件,# 现在通过all_features[:n_train]和all_features[n_train:]将他们分开test_features = nd.array(all_features[n_train:].values)train_labels = nd.array(train_data.SalePrice.values).reshape((-1,1))# 3.训练模型# 使用基本线性回归模型和平方损失函数训练模型loss = gloss.L2Loss()def get_net(): net = nn.Sequential() net.add(nn.Dense(1)) net.initialize() return net# 定义此次比赛中用来评价模型的对数均方根误差.def log_rmse(net,features,labels): # 将小于1的值设成1,使得取对数时数值更稳定 ''' Numpy中clip函数的使用.numpy.clip(a, a_min, a_max, out=None) 其中a是一个数组，后面两个参数分别表示最小和最大值，也就是说clip这个 函数将将数组中的元素限制在a_min, a_max之间，大于a_max的就使得它等 于 a_max，小于a_min,的就使得它等于a_min。 ''' clipped_preds = nd.clip(net(features),1,float('inf')) rmse = nd.sqrt(2 * loss(clipped_preds.log(),labels.log()).mean()) # asscalar():Convert an array of size 1 to its scalar equivalent. # 将大小为1的数组转换为其标量等效值 return rmse.asscalar()def train(net,train_features,train_labels,test_features,test_labels, num_epochs,learning_rate,weight_decay,batch_size): train_ls,test_ls = [],[] train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features,train_labels),batch_size,shuffle=True) # 使用Adam优化算法 trainer = gluon.Trainer(net.collect_params(),'adam',&#123;'learning_rate':learning_rate,'wd':weight_decay&#125;) for epoch in range(num_epochs): for X,y in train_iter: with autograd.record(): l = loss(net(X),y) l.backward() trainer.step(batch_size) train_ls.append(log_rmse(net,train_features,train_labels)) if test_labels is not None: test_ls.append(log_rmse(net,test_features,test_labels)) return train_ls,test_ls# 4.K折交叉验证def get_k_fold_data(k,i,X,y): # 返回第i折交叉验证时所需要的训练和验证数据 # 断言函数,做下判断,如果是false就报错退出 assert k &gt; 1 # 均分一下数据 fold_size = X.shape[0] // k X_train,y_train = None,None for j in range(k): # slice() 函数实现切片对象，主要用在切片操作函数里的参数传递。 idx = slice(j * fold_size,(j + 1) * fold_size) X_part,y_part = X[idx,:],y[idx] if j == 1: X_valid,y_valid = X_part,y_part elif X_train is None: X_train,y_train = X_part,y_part else: X_train = nd.concat(X_train,X_part,dim=0) y_train = nd.concat(y_train,y_part,dim=0) return X_train,y_train,X_valid,y_valid# K折交叉验证我们训练k次并返回训练和验证的平均误差def k_fold(k,X_train,y_train,num_epochs,learning_rate,weight_decay,batch_size): train_l_sum,valid_l_sum = 0,0 for i in range(k): data = get_k_fold_data(k,i,X_train,y_train) net = get_net() train_ls,valid_ls = train(net,*data,num_epochs,learning_rate,weight_decay,batch_size) train_l_sum += train_ls[-1] valid_l_sum += valid_ls[-1] if i == 0: ''' 我们先定义作图函数semilogy，其中y轴使用了对数尺度。 def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None, legend=None, figsize=(3.5, 2.5)): gb.set_figsize(figsize) gb.plt.xlabel(x_label) gb.plt.ylabel(y_label) gb.plt.semilogy(x_vals, y_vals) if x2_vals and y2_vals: gb.plt.semilogy(x2_vals, y2_vals, linestyle=':') gb.plt.legend(legend) ''' gb.semilogy(range(1,num_epochs + 1),train_ls,'epochs','rmse',range(1,num_epochs +1),valid_ls,['train','valid']) print('fold %d,train rmse: %f,valid rmse: %f' % (i,train_ls[-1],valid_ls[-1])) return train_l_sum / k,valid_l_sum / k# 5.模型选择# 我们使用一组未经调优的超参数并计算交叉验证误差。你可以改动这些超参数来尽可能减小平均测试误差。k,num_epochs,lr,weight_decay,batch_size = 10,165,5,0,60train_l,valid_l = k_fold(k,train_features,train_labels,num_epochs,lr, weight_decay,batch_size)print('%d-fold validation: avg train rmse: %f,avg valid rmse: %f' % (k,train_l,valid_l))'''有时候你会发现一组参数的训练误差可以达到很低，但是在K折交叉验证上的误差可能反而较高。这种现象很可能是由于过拟合造成的。因此，当训练误差降低时，我们要观察K折交叉验证上的误差是否也相应降低。'''# 6.预测并在kaggle提交结果def train_and_pred(train_features,test_features,train_labels,test_data, num_epochs,lr,weight_decay,batch_size): net = get_net() train_ls,_ = train(net,train_features,train_labels,None,None, num_epochs,lr,weight_decay,batch_size) gb.semilogy(range(1,num_epochs + 1),train_ls,'epochs','rmse') print('train rmse %f' % train_ls[-1]) preds = net(test_features).asnumpy() test_data['SalePrice'] = pd.Series(preds.reshape(1,-1)[0]) submission = pd.concat([test_data['Id'],test_data['SalePrice']],axis=1) submission.to_csv('submission.csv',index=False)train_and_pred(train_features,test_features,train_labels,test_data, num_epochs,lr,weight_decay,batch_size)'''上述代码执行完之后会生成一个“submission.csv”文件。这个文件是符合 Kaggle 比赛要求的提交格式的。这时，我们可以在 Kaggle 上把我们预测得出的结果进行提交，并且查看与测试数据集上真实房价（标签）的误差。具体来说有以下几个步骤：你需要登录 Kaggle 网站，访问房价预测比赛网页，并点击右侧“Submit Predictions”或“Late Submission”按钮。然后，点击页面下方“Upload Submission File”图标所在的虚线框选择需要提交的预测结果文件。最后，点击页面最下方的“Make Submission”按钮就可以查看结果了''' 参数[10,100,5,0,64]运行结果: fold 0,train rmse: 0.166232,valid rmse: 0.144298fold 1,train rmse: 0.166070,valid rmse: 0.144265fold 2,train rmse: 0.166147,valid rmse: 0.144306fold 3,train rmse: 0.166064,valid rmse: 0.144525fold 4,train rmse: 0.165943,valid rmse: 0.144174fold 5,train rmse: 0.166049,valid rmse: 0.144230fold 6,train rmse: 0.166298,valid rmse: 0.144140fold 7,train rmse: 0.166498,valid rmse: 0.144192fold 8,train rmse: 0.165994,valid rmse: 0.144347fold 9,train rmse: 0.165646,valid rmse: 0.14396310-fold validation: avg train rmse: 0.166094,avg valid rmse: 0.144244 参数[10,150,5,0,64]运行结果:fold 0,train rmse: 0.150604,valid rmse: 0.128320fold 1,train rmse: 0.150390,valid rmse: 0.128391fold 2,train rmse: 0.150571,valid rmse: 0.128409fold 3,train rmse: 0.150316,valid rmse: 0.128166fold 4,train rmse: 0.150575,valid rmse: 0.128311fold 5,train rmse: 0.150286,valid rmse: 0.128477fold 6,train rmse: 0.150312,valid rmse: 0.128338fold 7,train rmse: 0.150612,valid rmse: 0.128469fold 8,train rmse: 0.150454,valid rmse: 0.128422fold 9,train rmse: 0.150375,valid rmse: 0.12814510-fold validation: avg train rmse: 0.150450,avg valid rmse: 0.128345train rmse 0.145164 参数[10,165,5,0,50]运行结果:fold 0,train rmse: 0.139469,valid rmse: 0.120657fold 1,train rmse: 0.139487,valid rmse: 0.120587fold 2,train rmse: 0.139366,valid rmse: 0.120478fold 3,train rmse: 0.139568,valid rmse: 0.120741fold 4,train rmse: 0.139651,valid rmse: 0.120759fold 5,train rmse: 0.139555,valid rmse: 0.120640fold 6,train rmse: 0.139403,valid rmse: 0.120650fold 7,train rmse: 0.139626,valid rmse: 0.120719fold 8,train rmse: 0.139548,valid rmse: 0.120652fold 9,train rmse: 0.139596,valid rmse: 0.12069410-fold validation: avg train rmse: 0.139527,avg valid rmse: 0.120658train rmse 0.135256","categories":[{"name":"动手学深度学习","slug":"动手学深度学习","permalink":"http://120224.com/categories/动手学深度学习/"}],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://120224.com/tags/DeepLearning/"},{"name":"MXNet","slug":"MXNet","permalink":"http://120224.com/tags/MXNet/"},{"name":"Gluon","slug":"Gluon","permalink":"http://120224.com/tags/Gluon/"}]},{"title":"leetcode_01_twosum","slug":"leetcode-01-twosum","date":"2017-08-15T02:13:48.000Z","updated":"2018-12-31T05:50:00.418Z","comments":true,"path":"2017/08/15/leetcode-01-twosum/","link":"","permalink":"http://120224.com/2017/08/15/leetcode-01-twosum/","excerpt":"","text":"给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 示例: 给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9所以返回 [0, 1] 解题思路:方法一:暴力法暴力法很简单.遍历每个元素x,并查找是否存在一个值与target - x相等的目标元素.123456789101112class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; for(int i = 0;i &lt; nums.length;i++)&#123; for(int j = i + 1;j &lt; nums.length;j++)&#123; if(nums[j] == target - nums[i])&#123; return new int[] &#123;i,j&#125;; &#125; &#125; &#125; throw new IllegalArgumentException(\"No two sum solution\"); &#125;&#125; 复杂度分析: 时间复杂度:O(n2),对于每个元素,我们都试图通过遍历数组的其余部分来寻找它所对应的目标元素,这将耗费O(n)的时间.因此时间复杂度为O(n2) 空间复杂度:O(1) 方法二:两遍哈希表为了对运行时间复杂度进行优化，我们需要一种更有效的方法来检查数组中是否存在目标元素。如果存在，我们需要找出它的索引。保持数组中的每个元素与其索引相互对应的最好方法是什么？哈希表。 通过以空间换取速度的方式，我们可以将查找时间从O(n)降低到O(1)。哈希表正是为此目的而构建的，它支持以 近似 恒定的时间进行快速查找。我用“近似”来描述，是因为一旦出现冲突，查找用时可能会退化到O(n)。但只要你仔细地挑选哈希函数，在哈希表中进行查找的用时应当被摊销为O(1)。 一个简单的实现使用了两次迭代。在第一次迭代中，我们将每个元素的值和它的索引添加到表中。然后，在第二次迭代中，我们将检查每个元素所对应的目标元素（target−nums[i]）是否存在于表中。注意，该目标元素不能是nums[i]本身！123456789101112131415class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0;i &lt; nums.length;i++)&#123; map.put(nums[i],i); &#125; for(int i = 0;i &lt; nums.length;i++)&#123; int temp = target - nums[i]; if(map.containsKey(temp) &amp;&amp; map.get(temp) != i)&#123; return new int[] &#123;i,map.get(temp)&#125;; &#125; &#125; throw new IllegalArgumentException(\"No two sum solution\"); &#125;&#125; 复杂度分析： 时间复杂度：O(n)， 我们把包含有n个元素的列表遍历两次。由于哈希表将查找时间缩短到O(1)，所以时间复杂度为O(n)。 空间复杂度：O(n)， 所需的额外空间取决于哈希表中存储的元素数量，该表中存储了n个元素。 方法三：一遍哈希表事实证明，我们可以一次完成。在进行迭代并将元素插入到表中的同时，我们还会回过头来检查表中是否已经存在当前元素所对应的目标元素。如果它存在，那我们已经找到了对应解，并立即将其返回。12345678910111213class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0;i &lt; nums.length;i++)&#123; int temp = target - nums[i]; if(map.containsKey(temp))&#123; return new int[] &#123;map.get(temp),i&#125;; &#125; map.put(nums[i],i); &#125; throw new IllegalArgumentException(\"No two sum solution\"); &#125;&#125; 复杂度分析： 时间复杂度：O(n)， 我们只遍历了包含有n个元素的列表一次。在表中进行的每次查找只花费O(1)的时间。 空间复杂度：O(n)， 所需的额外空间取决于哈希表中存储的元素数量，该表最多需要存储n个元素。 采用方法 分别用时 1 44ms 2 11ms 3 4ms","categories":[{"name":"算法","slug":"算法","permalink":"http://120224.com/categories/算法/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://120224.com/tags/leetcode/"},{"name":"java","slug":"java","permalink":"http://120224.com/tags/java/"},{"name":"力扣","slug":"力扣","permalink":"http://120224.com/tags/力扣/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-06-22T05:14:25.000Z","updated":"2018-12-28T18:18:27.445Z","comments":true,"path":"2017/06/22/hello-world/","link":"","permalink":"http://120224.com/2017/06/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"技术","slug":"技术","permalink":"http://120224.com/categories/技术/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://120224.com/tags/hexo/"}]}]}