{"meta":{"title":"dengyang","subtitle":"dy","description":"120224.com# dengyang Deep Learning","author":"Young Teng","url":"http://120224.com"},"pages":[{"title":"友情链接","date":"2018-12-27T14:27:17.177Z","updated":"2018-12-27T14:27:17.177Z","comments":true,"path":"index.html","permalink":"http://120224.com/index.html","excerpt":"","text":""},{"title":"书单","date":"2018-12-27T14:29:38.582Z","updated":"2018-12-27T14:29:38.582Z","comments":false,"path":"books/index.html","permalink":"http://120224.com/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-12-27T14:29:38.586Z","updated":"2018-12-27T14:29:38.585Z","comments":true,"path":"links/index.html","permalink":"http://120224.com/links/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2018-12-27T14:29:38.588Z","updated":"2018-12-27T14:29:38.588Z","comments":false,"path":"/404.html","permalink":"http://120224.com//404.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-12-27T14:29:38.579Z","updated":"2018-12-27T14:29:38.579Z","comments":false,"path":"repository/index.html","permalink":"http://120224.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-12-27T14:29:38.585Z","updated":"2018-12-27T14:29:38.584Z","comments":false,"path":"tags/index.html","permalink":"http://120224.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-12-27T14:29:38.591Z","updated":"2018-12-27T14:29:38.591Z","comments":false,"path":"categories/index.html","permalink":"http://120224.com/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2018-12-28T19:37:08.656Z","updated":"2018-12-28T19:37:08.656Z","comments":true,"path":"about/index.html","permalink":"http://120224.com/about/index.html","excerpt":"","text":"个人详细介绍:一个矛盾纠结体处女座的苛求 + 天秤座的纠结一个没事总想胡乱鼓捣鼓捣的家伙爱好: 偶尔看看书,写些东西,发呆想写本关于自己的书,以后会更新在这个网站下 QQ: 568757336GithubID: 54dengyangWeChat: youngteng0923E-mail: youngteng@163.com"}],"posts":[{"title":"网站闲置了一年多之后的感想","slug":"the_thought_of_no_manage_web_one_half_year_later","date":"2018-12-26T23:35:59.000Z","updated":"2018-12-28T18:18:45.834Z","comments":true,"path":"2018/12/27/the_thought_of_no_manage_web_one_half_year_later/","link":"","permalink":"http://120224.com/2018/12/27/the_thought_of_no_manage_web_one_half_year_later/","excerpt":"","text":"其实我在2017年06/07月份就应经把120224.com这个域名注册了,同时也在同事彭川大神的影响下开始接触hexo+github.io这个静态博客系统.之后也是随意搞搞搞,没有什么大的动作.后来09月23日左右又开始跟着李沐大神学习Gluon深度学习课程,这些东西也就不了了之了.最近是看到别人的博客时,发现别人的博客挺漂亮的就想到了自己的.自己的一直没有经营,还是以前的老theme.因为之前修过了mac-pro,导致自己的博客文件没有备份保存下来,同时又想直接摒弃以前的主题,所以最近就直接又新建了一个新的主题.以后这个博客还是可以多来记录记录自己的技术学习过程和自己的生活点点滴滴的,也是极好的呢.同时自己也有喜欢记录的习惯,就是偶尔总是拖延症附体,所以也都是断断续续不系统的记录.有时候也总是想改掉这个坏毛病,所以这个博客也就成了自己改掉坏习惯的一个”见证人”吧.后面的路还很长,希望自己勿忘初心,砥砺前行,脚踏实地的,千万不要再次好高骛远了.加油! 邓先森 2018-12-27 08:20 石榴庄","categories":[{"name":"随笔","slug":"随笔","permalink":"http://120224.com/categories/随笔/"}],"tags":[{"name":"感想","slug":"感想","permalink":"http://120224.com/tags/感想/"}]},{"title":"<(￣︶￣)> 网站更新情况记录 <(￣︶￣)>","slug":"the_logs_of_web_update","date":"2017-12-28T18:12:01.000Z","updated":"2018-12-28T19:40:45.335Z","comments":true,"path":"2017/12/29/the_logs_of_web_update/","link":"","permalink":"http://120224.com/2017/12/29/the_logs_of_web_update/","excerpt":"","text":"2018-12-29:1.添加置顶功能.2.增添了日志发表时间,以前版本只到日期.3.添加了吴恩达课程和AstonZhang的友链.4.更改”沐神”为”李沐”,描述”~ 亚马逊 &amp; MXNet &amp; Gluon发起者 ~”改为”~ 亚马逊首席（principal）科学家，美国卡内基梅隆大学计算机系博士。~”.5.更改”~ B站课程 (经典) ~”为”~ B站《动手学深度学习》课程 (经典) ~”. 2018-12-28:1.将网站与七牛云连结,避免日后写文章添加图片的繁琐. 2018-12-27:1.添加评论功能,用了韩国的”来必力”.经过测试移动端貌似没有问题,就是pc端可能存在问题,To-do. 2018-12-26:1.将Next主题更新为Pure主题,重新开始.","categories":[{"name":"网站更新","slug":"网站更新","permalink":"http://120224.com/categories/网站更新/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://120224.com/tags/hexo/"}]},{"title":"kaggle上的房价预测竞赛练习,个人最好成绩达到0.15538 <未完待续>","slug":"test-of-kaggle-house-prices-predict","date":"2017-09-23T17:25:24.000Z","updated":"2018-12-29T17:56:20.058Z","comments":true,"path":"2017/09/24/test-of-kaggle-house-prices-predict/","link":"","permalink":"http://120224.com/2017/09/24/test-of-kaggle-house-prices-predict/","excerpt":"","text":"-- coding: utf-8 --@Time : 2017/09/23 3:14 PM@Author : dengyang@Email : youngteng@163.com@File : housePredict.py@Software: PyCharm1.获取和读取数据集导包import gluonbook as gbfrom mxnet import autograd,nd,gluon,initfrom mxnet.gluon import data as gdata,loss as gloss,nnimport numpy as npimport pandas as pd 读取数据train_data = pd.read_csv(‘./train.csv’)test_data = pd.read_csv(‘./test.csv’) 查看下train和test数据的shape,规格大小print(train_data.shape)print(test_data.shape) 查看下训练样本前四个样本的前四个特征,后两个特征和标签‘’’iloc和loc的区别： iloc，完全基于位置的索引. iloc的用法完全和numpy中的数字索引一样，开闭区间的逻辑也和Python是相同的。 要注意的是，如果iloc方括号中直接给定一个数字或者一个slice的话，默认索引的是行。 其中数字的情况会返回一个Series iloc主要使用数字来索引数据，而不能使用字符型的标签来索引数据。 而loc则刚好相反，只能使用字符型标签来索引数据，不能使用数字来 索引数据，不过有特殊情况，当数据框dataframe的行标签或者列标 签为数字，loc就可以来其来索引。 ‘’’print(train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]]) 将所有数据的训练和测试数据的79个特征按样本连结all_features = pd.concat((train_data.iloc[:,1:-1],test_data.iloc[:,1:])) 2.预处理数据对连续数值的特征做标准化:假设特征在整个数据集上的均值μ,标准差σ.我们可以将特征中每个值先减去μ,再除以σ得到标准化后的每一个特征值,缺失值替换成该特征的均值.下面的含义是:all_features的类型如果不是object类型则将特征的索引(index)传递给numeric_featuresnumeric_features = all_features.dtypes[all_features.dtypes != ‘object’].index‘’’apply:TO-DO‘’’all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std())) 下面代码含义:将all_features中含有NA的值用all_features的均值进行填充.all_features = all_features.fillna(all_features.mean()) 将离散数值转换成指示特征.如:特征A里面有两个不同的离散值1和2,那么这一步转换将去掉A特征,并新加两个新特征A_1和A_2,其值为0或1.dummy_na=True,将缺失值也当做合法的特征值并为其创建指示特征all_features = pd.get_dummies(all_features,dummy_na=True)print(all_features.shape) 此时将特征从79维增加到331维通过values属性得到NumPy格式的数据,并转成NDArray方便后继训练n_train = train_data.shape[0]train_features = nd.array(all_features[:n_train].values) 因为之前将train和test所有的数据都合并成了一个文件,现在通过all_features[:n_train]和all_features[n_train:]将他们分开test_features = nd.array(all_features[n_train:].values)train_labels = nd.array(train_data.SalePrice.values).reshape((-1,1)) 3.训练模型使用基本线性回归模型和平方损失函数训练模型loss = gloss.L2Loss() def get_net(): net = nn.Sequential() net.add(nn.Dense(1)) net.initialize() return net 定义此次比赛中用来评价模型的对数均方根误差.def log_rmse(net,features,labels): # 将小于1的值设成1,使得取对数时数值更稳定 &apos;&apos;&apos; Numpy中clip函数的使用.numpy.clip(a, a_min, a_max, out=None) 其中a是一个数组，后面两个参数分别表示最小和最大值，也就是说clip这个 函数将将数组中的元素限制在a_min, a_max之间，大于a_max的就使得它等 于 a_max，小于a_min,的就使得它等于a_min。 &apos;&apos;&apos; clipped_preds = nd.clip(net(features),1,float(&apos;inf&apos;)) rmse = nd.sqrt(2 * loss(clipped_preds.log(),labels.log()).mean()) # asscalar():Convert an array of size 1 to its scalar equivalent. # 将大小为1的数组转换为其标量等效值 return rmse.asscalar() def train(net,train_features,train_labels,test_features,test_labels, num_epochs,learning_rate,weight_decay,batch_size): train_ls,test_ls = [],[] train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features,train_labels),batch_size,shuffle=True) # 使用Adam优化算法 trainer = gluon.Trainer(net.collect_params(),&apos;adam&apos;,{&apos;learning_rate&apos;:learning_rate,&apos;wd&apos;:weight_decay}) for epoch in range(num_epochs): for X,y in train_iter: with autograd.record(): l = loss(net(X),y) l.backward() trainer.step(batch_size) train_ls.append(log_rmse(net,train_features,train_labels)) if test_labels is not None: test_ls.append(log_rmse(net,test_features,test_labels)) return train_ls,test_ls 4.K折交叉验证def get_k_fold_data(k,i,X,y): # 返回第i折交叉验证时所需要的训练和验证数据 # 断言函数,做下判断,如果是false就报错退出 assert k &gt; 1 # 均分一下数据 fold_size = X.shape[0] // k X_train,y_train = None,None for j in range(k): # slice() 函数实现切片对象，主要用在切片操作函数里的参数传递。 idx = slice(j * fold_size,(j + 1) * fold_size) X_part,y_part = X[idx,:],y[idx] if j == 1: X_valid,y_valid = X_part,y_part elif X_train is None: X_train,y_train = X_part,y_part else: X_train = nd.concat(X_train,X_part,dim=0) y_train = nd.concat(y_train,y_part,dim=0) return X_train,y_train,X_valid,y_valid K折交叉验证我们训练k次并返回训练和验证的平均误差def k_fold(k,X_train,y_train,num_epochs,learning_rate,weight_decay,batch_size): train_l_sum,valid_l_sum = 0,0 for i in range(k): data = get_k_fold_data(k,i,X_train,y_train) net = get_net() train_ls,valid_ls = train(net,*data,num_epochs,learning_rate,weight_decay,batch_size) train_l_sum += train_ls[-1] valid_l_sum += valid_ls[-1] if i == 0: ‘’’ 我们先定义作图函数semilogy，其中y轴使用了对数尺度。 def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None, legend=None, figsize=(3.5, 2.5)): gb.set_figsize(figsize) gb.plt.xlabel(x_label) gb.plt.ylabel(y_label) gb.plt.semilogy(x_vals, y_vals) if x2_vals and y2_vals: gb.plt.semilogy(x2_vals, y2_vals, linestyle=’:’) gb.plt.legend(legend) ‘’’ gb.semilogy(range(1,num_epochs + 1),train_ls,’epochs’,’rmse’,range(1,num_epochs +1),valid_ls,[‘train’,’valid’]) print(‘fold %d,train rmse: %f,valid rmse: %f’ % (i,train_ls[-1],valid_ls[-1])) return train_l_sum / k,valid_l_sum / k 5.模型选择我们使用一组未经调优的超参数并计算交叉验证误差。你可以改动这些超参数来尽可能减小平均测试误差。k,num_epochs,lr,weight_decay,batch_size = 10,100,5,0,64train_l,valid_l = k_fold(k,train_features,train_labels,num_epochs,lr, weight_decay,batch_size)print(‘%d-fold validation: avg train rmse: %f,avg valid rmse: %f’ % (k,train_l,valid_l))‘’’有时候你会发现一组参数的训练误差可以达到很低，但是在K折交叉验证上的误差可能反而较高。这种现象很可能是由于过拟合造成的。因此，当训练误差降低时，我们要观察K折交叉验证上的误差是否也相应降低。‘’’ 6.预测并在kaggle提交结果def train_and_pred(train_features,test_features,train_labels,test_data, num_epochs,lr,weight_decay,batch_size): net = get_net() train_ls,_ = train(net,train_features,train_labels,None,None, num_epochs,lr,weight_decay,batch_size) gb.semilogy(range(1,num_epochs + 1),train_ls,’epochs’,’rmse’) print(‘train rmse %f’ % train_ls[-1]) preds = net(test_features).asnumpy() test_data[‘SalePrice’] = pd.Series(preds.reshape(1,-1)[0]) submission = pd.concat([test_data[‘Id’],test_data[‘SalePrice’]],axis=1) submission.to_csv(‘submission.csv’,index=False) train_and_pred(train_features,test_features,train_labels,test_data, num_epochs,lr,weight_decay,batch_size)‘’’上述代码执行完之后会生成一个“submission.csv”文件。这个文件是符合 Kaggle 比赛要求的提交格式的。这时，我们可以在 Kaggle 上把我们预测得出的结果进行提交，并且查看与测试数据集上真实房价（标签）的误差。具体来说有以下几个步骤：你需要登录 Kaggle 网站，访问房价预测比赛网页，并点击右侧“Submit Predictions”或“Late Submission”按钮。然后，点击页面下方“Upload Submission File”图标所在的虚线框选择需要提交的预测结果文件。最后，点击页面最下方的“Make Submission”按钮就可以查看结果了‘’’ 参数[10,100,5,0,64]运行结果: fold 0,train rmse: 0.166232,valid rmse: 0.144298fold 1,train rmse: 0.166070,valid rmse: 0.144265fold 2,train rmse: 0.166147,valid rmse: 0.144306fold 3,train rmse: 0.166064,valid rmse: 0.144525fold 4,train rmse: 0.165943,valid rmse: 0.144174fold 5,train rmse: 0.166049,valid rmse: 0.144230fold 6,train rmse: 0.166298,valid rmse: 0.144140fold 7,train rmse: 0.166498,valid rmse: 0.144192fold 8,train rmse: 0.165994,valid rmse: 0.144347fold 9,train rmse: 0.165646,valid rmse: 0.14396310-fold validation: avg train rmse: 0.166094,avg valid rmse: 0.144244 参数[10,150,5,0,64]运行结果:fold 0,train rmse: 0.150604,valid rmse: 0.128320fold 1,train rmse: 0.150390,valid rmse: 0.128391fold 2,train rmse: 0.150571,valid rmse: 0.128409fold 3,train rmse: 0.150316,valid rmse: 0.128166fold 4,train rmse: 0.150575,valid rmse: 0.128311fold 5,train rmse: 0.150286,valid rmse: 0.128477fold 6,train rmse: 0.150312,valid rmse: 0.128338fold 7,train rmse: 0.150612,valid rmse: 0.128469fold 8,train rmse: 0.150454,valid rmse: 0.128422fold 9,train rmse: 0.150375,valid rmse: 0.12814510-fold validation: avg train rmse: 0.150450,avg valid rmse: 0.128345train rmse 0.145164 参数[10,165,5,0,50]运行结果:fold 0,train rmse: 0.139469,valid rmse: 0.120657fold 1,train rmse: 0.139487,valid rmse: 0.120587fold 2,train rmse: 0.139366,valid rmse: 0.120478fold 3,train rmse: 0.139568,valid rmse: 0.120741fold 4,train rmse: 0.139651,valid rmse: 0.120759fold 5,train rmse: 0.139555,valid rmse: 0.120640fold 6,train rmse: 0.139403,valid rmse: 0.120650fold 7,train rmse: 0.139626,valid rmse: 0.120719fold 8,train rmse: 0.139548,valid rmse: 0.120652fold 9,train rmse: 0.139596,valid rmse: 0.12069410-fold validation: avg train rmse: 0.139527,avg valid rmse: 0.120658train rmse 0.135256","categories":[{"name":"动手学深度学习","slug":"动手学深度学习","permalink":"http://120224.com/categories/动手学深度学习/"}],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://120224.com/tags/DeepLearning/"},{"name":"MXNet","slug":"MXNet","permalink":"http://120224.com/tags/MXNet/"},{"name":"Gluon","slug":"Gluon","permalink":"http://120224.com/tags/Gluon/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-06-22T05:14:25.000Z","updated":"2018-12-28T18:18:27.445Z","comments":true,"path":"2017/06/22/hello-world/","link":"","permalink":"http://120224.com/2017/06/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"技术","slug":"技术","permalink":"http://120224.com/categories/技术/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://120224.com/tags/hexo/"}]}]}